{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Tweet Insult Predictor",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Load Data",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "train \u003d pd.read_csv(\u0027./data/insult_train.csv\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "train.sample(10)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Train Pipeline",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\n\npipeline \u003d Pipeline([\n    (\u0027vect\u0027, CountVectorizer()),\n    (\u0027clf\u0027, SGDClassifier(loss\u003d\u0027log\u0027,max_iter\u003d1000, tol\u003d1e-3)),\n    ])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\n\nparameters \u003d {\n    \u0027vect__min_df\u0027: (\n        5,\n        10,\n        15,\n    ),\n    \u0027vect__max_df\u0027: (\n        0.5, \n        0.75,\n        1.0,\n    ),\n    \u0027clf__alpha\u0027: np.logspace(-5,3,3),\n    }",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.model_selection import GridSearchCV\n\ngrid_search \u003d GridSearchCV(pipeline, parameters, cv\u003d5,\n                               n_jobs\u003d-1, verbose\u003d1,return_train_score\u003dTrue)\n\ngrid_search.fit(train.Comment, train.Insult )",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "data": {
            "text/plain": "[\u0027./output/model.pkl\u0027]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 22
        }
      ],
      "source": "# save model\nfrom sklearn.externals import joblib\njoblib.dump(grid_search.best_estimator_, \u0027./output/model.pkl\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Using a model",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "source": "# load model\nmodel \u003d joblib.load(\u0027./output/model.pkl\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Predict in test set",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Score on test set: 0.81\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "test \u003d pd.read_csv(\u0027./data/insult_test.csv\u0027)\n\n# predict\npreds \u003d model.predict_proba(test.Comment)\ntest[\u0027Insult_proba\u0027] \u003d preds[:,1] #insult prob is in second column\n\n# print score\ntest_score \u003d model.score(test.Comment, test.Insult)\nprint(f\u0027Score on test set: {test_score:.2f}\u0027)\n\n# save preds\ntest.to_csv(\u0027./output/insult_test_pred.csv\u0027)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Get word sentiment",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "words \u003d model.named_steps[\u0027vect\u0027].get_feature_names() # all words\ncoefs \u003d model.named_steps[\u0027clf\u0027].coef_.reshape(-1) # coefficent per word\nword_sentiment \u003d pd.DataFrame({\u0027sentiment\u0027:coefs*-1,},index\u003dwords) #sentiment is low when insult coefficient is high\nword_sentiment.to_csv(\u0027./output/word_sentiment.csv\u0027)\nword_sentiment.sort_values(by\u003d\u0027sentiment\u0027).head(10)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Sentence predictor",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "sentence \u003d \u0027Your mother was a hamster and your father smelt like elderberries\u0027\n\nsen_list \u003d [sentence] # model expects a list of sentences\nprobs \u003d model.predict_proba(sen_list)\ninsult_prob \u003d probs[0,1] # row 0 col 1 contains the insult prob\nprint(f\u0027Insult probability: {insult_prob:.2f}\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}