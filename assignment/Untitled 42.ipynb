{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Insult Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/insult_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>20120529223518Z</td>\n",
       "      <td>\"Just like Huff Bochy thinks Theriot  a player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619001525Z</td>\n",
       "      <td>\"I hope they hurt that fucking pig.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"MASSIVE PISSTAK*\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>0</td>\n",
       "      <td>20120529031217Z</td>\n",
       "      <td>\"Animal Planet told that Mermaids are real.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619040445Z</td>\n",
       "      <td>\"Franklin street #fuckwitme\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0</td>\n",
       "      <td>20120618215525Z</td>\n",
       "      <td>\"May he eat shit and &lt;i&gt;live&lt;/i&gt;.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1</td>\n",
       "      <td>20120612123016Z</td>\n",
       "      <td>\"Maybe you should read that\\xa0first sentence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>0</td>\n",
       "      <td>20120529034509Z</td>\n",
       "      <td>\"A few Thunder fans here don't seem to want to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619184505Z</td>\n",
       "      <td>\"LeBron, no matter who says what, you are an i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"I\\\\'m single, and but when I haven\\\\'t been, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "472        0  20120529223518Z   \n",
       "3125       0  20120619001525Z   \n",
       "2992       0              NaN   \n",
       "3055       0  20120529031217Z   \n",
       "2374       0  20120619040445Z   \n",
       "809        0  20120618215525Z   \n",
       "1496       1  20120612123016Z   \n",
       "2875       0  20120529034509Z   \n",
       "3843       0  20120619184505Z   \n",
       "1504       0              NaN   \n",
       "\n",
       "                                                Comment  \n",
       "472   \"Just like Huff Bochy thinks Theriot  a player...  \n",
       "3125               \"I hope they hurt that fucking pig.\"  \n",
       "2992                                 \"MASSIVE PISSTAK*\"  \n",
       "3055       \"Animal Planet told that Mermaids are real.\"  \n",
       "2374                       \"Franklin street #fuckwitme\"  \n",
       "809                  \"May he eat shit and <i>live</i>.\"  \n",
       "1496  \"Maybe you should read that\\xa0first sentence ...  \n",
       "2875  \"A few Thunder fans here don't seem to want to...  \n",
       "3843  \"LeBron, no matter who says what, you are an i...  \n",
       "1504  \"I\\\\'m single, and but when I haven\\\\'t been, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier(loss='log',max_iter=1000, tol=1e-3)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "parameters = {\n",
    "    'vect__min_df': (\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "    ),\n",
    "    'vect__max_df': (\n",
    "        0.5, \n",
    "        0.75,\n",
    "        1.0,\n",
    "    ),\n",
    "    'clf__alpha': np.logspace(-5,3,3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._state=None, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__min_df': (5, 10, 15), 'vect__max_df': (0.5, 0.75, 1.0), 'clf__alpha': array([1.e-05, 1.e-01, 1.e+03])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                               n_jobs=-1, verbose=1,return_train_score=True)\n",
    "\n",
    "grid_search.fit(train.Comment, train.Insult )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_search.best_estimator_, '../output/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = joblib.load('../output/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.81\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../data/insult_test.csv')\n",
    "\n",
    "# predict\n",
    "preds = model.predict_proba(test.Comment)\n",
    "test['Insult_proba'] = preds[:,1] #insult prob is in second column\n",
    "\n",
    "# print score\n",
    "test_score = model.score(test.Comment, test.Insult)\n",
    "print(f'Score on test set: {test_score:.2f}')\n",
    "\n",
    "# save preds\n",
    "test.to_csv('../output/insult_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get word sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asshole</th>\n",
       "      <td>-33.527743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dumb</th>\n",
       "      <td>-33.516357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faggot</th>\n",
       "      <td>-32.661423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moron</th>\n",
       "      <td>-29.960590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loser</th>\n",
       "      <td>-28.423332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>-28.201897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moronic</th>\n",
       "      <td>-26.717284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idiot</th>\n",
       "      <td>-25.894837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy</th>\n",
       "      <td>-24.539291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retards</th>\n",
       "      <td>-24.124035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "asshole -33.527743\n",
       "dumb    -33.516357\n",
       "faggot  -32.661423\n",
       "moron   -29.960590\n",
       "loser   -28.423332\n",
       "sister  -28.201897\n",
       "moronic -26.717284\n",
       "idiot   -25.894837\n",
       "greedy  -24.539291\n",
       "retards -24.124035"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = model.named_steps['vect'].get_feature_names() # all words\n",
    "coefs = model.named_steps['clf'].coef_.reshape(-1) # coefficent per word\n",
    "word_sentiment = pd.DataFrame({'sentiment':coefs*-1,},index=words) #sentiment is low when insult coefficient is high\n",
    "word_sentiment.to_csv('../output/word_sentiment.csv')\n",
    "word_sentiment.sort_values(by='sentiment').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insult probability: 1.00\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Your mother was a hamster and your father smelt like elderberries'\n",
    "\n",
    "sen_list = [sentence] # model expects a list of sentences\n",
    "probs = model.predict_proba(sen_list)\n",
    "insult_prob = probs[0,1] # row 0 col 1 contains the insult prob\n",
    "print(f'Insult probability: {insult_prob:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
